"""
Corpus Importer for TextHelper
Bu araÃ§, elinizdeki herhangi bir metin dosyasÄ±nÄ± (Kitap, Wikipedia, Loglar)
tarayarak yeni kelimeler Ã¶ÄŸrenir ve sÃ¶zlÃ¼ÄŸe ekler.

KullanÄ±m:
    python corpus_importer.py "dosya_yolu.txt"
"""

import sys
import os
import json
import re
from collections import Counter

def clean_text(text):
    # Sadece TÃ¼rkÃ§e karakterler ve harfler kalsÄ±n
    text = text.lower()
    text = re.sub(r'[^a-zcCjwÄŸÃ¼Ã¶ÅŸÄ±Ä°ÄÃœÃ–ÅÃ‡\s]', '', text)
    return text

def import_corpus(file_path):
    print(f"ğŸ“– Dosya okunuyor: {file_path}")
    
    if not os.path.exists(file_path):
        print("âŒ Dosya bulunamadÄ±!")
        return

    # 1. Metni Oku
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except UnicodeDecodeError:
        try:
            with open(file_path, 'r', encoding='cp1254') as f:
                content = f.read()
        except:
            print("âŒ Dosya kodlamasÄ± okunamadÄ± (UTF-8 veya CP1254 deÄŸil).")
            return

    print(f"âœ… Okunan karakter sayÄ±sÄ±: {len(content)}")

    # 2. Temizle ve Kelimelere AyÄ±r
    print("ğŸ§¹ Metin temizleniyor...")
    cleaned = clean_text(content)
    words = cleaned.split()
    print(f"ğŸ“Š Bulunan toplam kelime: {len(words)}")

    # 3. Frekans Analizi
    word_counts = Counter(words)
    print(f"ğŸ” Benzersiz kelime sayÄ±sÄ±: {len(word_counts)}")

    # 4. Mevcut SÃ¶zlÃ¼ÄŸÃ¼ YÃ¼kle
    current_dict_path = os.path.join("improvements", "turkish_dictionary.json")
    if not os.path.exists(current_dict_path):
        # EÄŸer yoksa yeni oluÅŸtur
        current_data = {"words": []}
    else:
        try:
            with open(current_dict_path, 'r', encoding='utf-8') as f:
                current_data = json.load(f)
        except:
            current_data = {"words": []}

    existing_words = set(current_data.get("words", []))
    print(f"ğŸ“š Mevcut sÃ¶zlÃ¼k boyutu: {len(existing_words)} kelime")

    # 5. Yeni Kelimeleri Ekle
    new_words_count = 0
    for word, count in word_counts.items():
        if word not in existing_words and len(word) > 1:
            if count > 1: # Sadece 1'den fazla geÃ§enleri ekle (gÃ¼rÃ¼ntÃ¼yÃ¼ azaltmak iÃ§in)
                existing_words.add(word)
                new_words_count += 1
    
    # 6. Kaydet
    print(f"ğŸ’¾ Kaydediliyor... ({new_words_count} yeni kelime eklendi)")
    
    # Listeye Ã§evir ve sÄ±rala
    sorted_words = sorted(list(existing_words))
    
    with open(current_dict_path, 'w', encoding='utf-8') as f:
        json.dump({"words": sorted_words}, f, ensure_ascii=False) # indent=0 for smaller size

    print("âœ… Ä°ÅLEM TAMAMLANDI!")
    print(f"ğŸš€ Yeni SÃ¶zlÃ¼k Boyutu: {len(sorted_words)} kelime")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("KullanÄ±m: python corpus_importer.py <dosya_yolu>")
    else:
        import_corpus(sys.argv[1])
