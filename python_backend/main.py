"""
TextHelper ULTIMATE - Hybrid: Transformer + Elasticsearch + FastAPI
En iyi Ã§Ã¶zÃ¼m - Production ready
"""

from fastapi import FastAPI, WebSocket, HTTPException, Request, APIRouter
from starlette.websockets import WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.base import BaseHTTPMiddleware
from fastapi.responses import Response
from pydantic import BaseModel
from typing import List, Optional, Dict
import uvicorn
import asyncio
from datetime import datetime
import json
import os
import sys
from contextlib import asynccontextmanager
from fastapi.responses import ORJSONResponse

# Gzip Middleware (Optional)
try:
    from starlette.middleware.gzip import GZipMiddleware
except ImportError:
    try:
        from fastapi.middleware.gzip import GZipMiddleware
    except ImportError:
        GZipMiddleware = None

# Logger Import
from logger_config import logger

# Improvements modÃ¼llerini ekle
sys.path.append(os.path.join(os.path.dirname(__file__), 'improvements'))
try:
    from redis_cache import cache
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    cache = None


try:
    from large_dictionary import large_dictionary
    LARGE_DICT_AVAILABLE = True
except ImportError:
    LARGE_DICT_AVAILABLE = False
    large_dictionary = None

# YENI: Medium Dictionary (Reliable Fallback)
try:
    from medium_dictionary import medium_dictionary
    MEDIUM_DICT_AVAILABLE = True
except ImportError:
    MEDIUM_DICT_AVAILABLE = False
    medium_dictionary = None

try:
    from ml_learning import ml_learning
    ML_LEARNING_AVAILABLE = True
except ImportError:
    ML_LEARNING_AVAILABLE = False
    ml_learning = None

try:
    from transformer_model import transformer_model
    REAL_TRANSFORMER_AVAILABLE = True
except ImportError:
    REAL_TRANSFORMER_AVAILABLE = False
    transformer_model = None

try:
    from elasticsearch_setup import es_manager
    ES_MANAGER_AVAILABLE = True
except ImportError:
    ES_MANAGER_AVAILABLE = False
    es_manager = None

try:
    from advanced_ngram import advanced_ngram
    ADVANCED_NGRAM_AVAILABLE = True
except ImportError:
    ADVANCED_NGRAM_AVAILABLE = False
    advanced_ngram = None

# Eski context analyzer yerine geliÅŸmiÅŸ olana Ã¶ncelik veriyoruz
try:
    from context_analyzer import context_analyzer
    CONTEXT_ANALYZER_AVAILABLE = True
except ImportError:
    CONTEXT_ANALYZER_AVAILABLE = False
    context_analyzer = None

try:
    from advanced_context_completion import advanced_context_completer
    ADVANCED_CONTEXT_AVAILABLE = True
except ImportError:
    ADVANCED_CONTEXT_AVAILABLE = False
    advanced_context_completer = None

try:
    from advanced_ranking import advanced_ranking
    ADVANCED_RANKING_AVAILABLE = True
except ImportError:
    ADVANCED_RANKING_AVAILABLE = False
    advanced_ranking = None

try:
    from advanced_fuzzy import advanced_fuzzy
    ADVANCED_FUZZY_AVAILABLE = True
except ImportError:
    ADVANCED_FUZZY_AVAILABLE = False
    advanced_fuzzy = None

try:
    from phrase_completion import PhraseCompleter
    # Dictionary referansÄ±nÄ± geÃ§ (son kelime iÃ§in genel arama iÃ§in)
    if LARGE_DICT_AVAILABLE and large_dictionary:
        phrase_completer = PhraseCompleter(dictionary=large_dictionary)
    else:
        phrase_completer = PhraseCompleter()
    PHRASE_COMPLETION_AVAILABLE = True
except ImportError:
    PHRASE_COMPLETION_AVAILABLE = False
    phrase_completer = None

try:
    from domain_dictionaries import domain_manager
    DOMAIN_DICT_AVAILABLE = True
except ImportError:
    DOMAIN_DICT_AVAILABLE = False
    domain_manager = None

try:
    from security import security_manager
    SECURITY_AVAILABLE = True
except ImportError:
    SECURITY_AVAILABLE = False
    security_manager = None

try:
    from performance_optimizer import performance_optimizer
    PERFORMANCE_AVAILABLE = True
except ImportError:
    PERFORMANCE_AVAILABLE = False
    performance_optimizer = None

try:
    from emoji_suggestions import emoji_suggester
    EMOJI_AVAILABLE = True
except ImportError:
    EMOJI_AVAILABLE = False
    emoji_suggester = None

try:
    from smart_templates import smart_template_manager
    SMART_TEMPLATES_AVAILABLE = True
except ImportError:
    SMART_TEMPLATES_AVAILABLE = False
    smart_template_manager = None

try:
    from sentiment_analyzer import sentiment_analyzer
    SENTIMENT_AVAILABLE = True
except ImportError:
    SENTIMENT_AVAILABLE = False
    sentiment_analyzer = None

# YENÄ°: Advanced Context Completion
try:
    from advanced_context_completion import AdvancedContextCompleter
    if LARGE_DICT_AVAILABLE and large_dictionary:
        advanced_context_completer = AdvancedContextCompleter(dictionary=large_dictionary)
    else:
        advanced_context_completer = AdvancedContextCompleter()
    ADVANCED_CONTEXT_AVAILABLE = True
except ImportError:
    ADVANCED_CONTEXT_AVAILABLE = False
    advanced_context_completer = None

# YENÄ°: ML Ranking
try:
    from ml_ranking import ml_ranking
    ML_RANKING_AVAILABLE = True
except ImportError:
    ML_RANKING_AVAILABLE = False
    ml_ranking = None

# YENÄ°: Trie Index
try:
    from trie_index import trie_index, TrieIndex
    TRIE_AVAILABLE = True
except ImportError:
    TRIE_AVAILABLE = False
    trie_index = None
    TrieIndex = None

# YENÄ°: Relevance Filter
try:
    from relevance_filter import relevance_filter
    RELEVANCE_FILTER_AVAILABLE = True
except ImportError:
    RELEVANCE_FILTER_AVAILABLE = False
    relevance_filter = None

# WhatsApp/iPhone benzeri: 1-2 karakter iÃ§in Ã¶ncelikli Ã¶neriler (merhaba, nasÄ±l, ...)
try:
    from smart_completions import get_smart_completions
    SMART_COMPLETIONS_AVAILABLE = True
except ImportError:
    SMART_COMPLETIONS_AVAILABLE = False
    get_smart_completions = None

# iPhone benzeri: yaygÄ±n kelime Ã¶nceliklendirmesi (hangi, merhaba, nasÄ±l vb.)
try:
    from common_words import is_common, first_word_common
    COMMON_WORDS_AVAILABLE = True
except ImportError:
    COMMON_WORDS_AVAILABLE = False
    is_common = lambda w: False
    first_word_common = lambda t: False

# ============================================
# LIFESPAN (STARTUP/SHUTDOWN)
# ============================================
@asynccontextmanager
async def lifespan(app: FastAPI):
    # --- STARTUP ---
    """Uygulama baÅŸlatÄ±ldÄ±ÄŸÄ±nda"""
    logger.info("=" * 60)
    logger.info("TextHelper ULTIMATE - Hybrid System")
    logger.info("Transformer + Elasticsearch + FastAPI")
    logger.info("=" * 60)
    
    # Transformer modelini yÃ¼kle - LAZY: Sadece USE_TRANSFORMER=true ise
    # Transformer Ã§ok aÄŸÄ±r (CPU/GPU), varsayÄ±lan olarak kapalÄ±
    use_transformer = os.getenv("USE_TRANSFORMER", "false").lower() == "true"
    if use_transformer and REAL_TRANSFORMER_AVAILABLE and transformer_model:
        try:
            logger.info("Transformer modeli yukleniyor (USE_TRANSFORMER=true)...")
            logger.info("NOT: Transformer CPU/GPU kullanimini artirir - sadece gerektiginde aktif edin")
            await transformer_model.load_model(timeout_seconds=30)  # 30s timeout (daha hÄ±zlÄ±)
            if transformer_model.model_loaded:
                logger.info("RealTransformerModel yuklendi ve aktif!")
            else:
                logger.info("Transformer yuklenemedi, diger yontemler kullanilacak")
            
            # Sonra TransformerPredictor'Ä± yÃ¼kle (sadece transformer aktifse)
            if transformer_model.model_loaded:
                await transformer_predictor.load_model()
        except Exception as e:
            logger.warning(f"Transformer yukleme hatasi: {e}")
            logger.info("Transformer olmadan devam ediliyor...")
    else:
        logger.info("Transformer devre disi (USE_TRANSFORMER=false) - CPU/GPU kullanimini azaltir")
        logger.info("Transformer'i aktif etmek icin: TUM_OZELLIKLERLE_BASLAT.bat kullanin")
    
    # Elasticsearch'e baÄŸlan (opsiyonel - normal durum)
    try:
        await elasticsearch_predictor.connect_elasticsearch()
        
        if elasticsearch_predictor.es_client:
            logger.info("Elasticsearch baglantisi basarili!")
        else:
            # Normal durum - yerel sÃ¶zlÃ¼k kullanÄ±lacak (Elasticsearch opsiyonel)
            logger.info("Elasticsearch kullanilamiyor, yerel sozluk kullanilacak (normal)")
    except Exception as e:
        # Normal durum - yerel sÃ¶zlÃ¼k kullanÄ±lacak (Elasticsearch opsiyonel)
        logger.info("Elasticsearch kullanilamiyor, yerel sozluk kullanilacak (normal)")
    
    # ES Manager varsa kelimeleri index'le
    if ES_MANAGER_AVAILABLE and es_manager and hasattr(es_manager, 'available') and es_manager.available:
        # Ä°lk baÅŸlatmada kelimeleri index'le (opsiyonel)
        logger.info("Elasticsearch Manager aktif - kelimeleri index'lemek icin /index_words endpoint'ini kullanin")
    
    # YENÄ°: Trie Index oluÅŸtur (performans iÃ§in)
    if TRIE_AVAILABLE and TrieIndex and LARGE_DICT_AVAILABLE and large_dictionary:
        try:
            logger.info("Trie index oluÅŸturuluyor (ultra hÄ±zlÄ± arama iÃ§in)...")
            trie_index.build_from_words(
                large_dictionary.words,
                large_dictionary.word_frequencies
            )
            stats = trie_index.get_stats()
            logger.info(f"Trie index hazÄ±r: {stats.get('word_count', 0):,} kelime, {stats.get('node_count', 0):,} node")
        except Exception as e:
            logger.warning(f"Trie index oluÅŸturma hatasÄ±: {e}")
    
    # N-gram modeli istatistikleri
    if ADVANCED_NGRAM_AVAILABLE and advanced_ngram and hasattr(advanced_ngram, 'get_stats'):
        try:
            stats = advanced_ngram.get_stats()
            if stats and isinstance(stats, dict):
                logger.info(f"N-gram Modeli: {stats.get('bigrams', 0)} bigram, {stats.get('trigrams', 0)} trigram, {stats.get('quadgrams', 0)} quadgram")
        except Exception as e:
            logger.warning(f"N-gram stats hatasi: {e}")
    
    # Production mode kontrolÃ¼
    is_production = os.getenv("USE_TRANSFORMER", "false").lower() == "true" and os.getenv("ENABLE_HEAVY_FEATURES", "false").lower() == "true"
    
    logger.info("=" * 70)
    if is_production:
        logger.info("ðŸš€ PRODUCTION MODE - MUSTERI HIZMETLERI ICIN HAZIR!")
        logger.info("=" * 70)
        logger.info("[PRODUCTION] Tum ozellikler aktif")
        logger.info("[PRODUCTION] 1M+ kelime hedefi")
        logger.info("[PRODUCTION] Vodafone, Turkcell, vb. entegrasyon icin hazir")
    else:
        logger.info("âœ… SISTEM HAZIR (Minimal Mode)")
        logger.info("=" * 70)
        logger.info("Production mode icin: PRODUCTION_BASLAT.bat kullanin")
    logger.info("=" * 70)
    logger.info("[OK] Sistem hazir!")
    logger.info("API Docs: http://localhost:8000/docs")
    logger.info("WebSocket: ws://localhost:8000/ws")
    logger.info("Health: http://localhost:8000/health")
    logger.info(f"REDIS_PORT: {os.getenv('REDIS_PORT', '6379')}")
    logger.info("YENI OZELLIKLER:")
    
    if ADVANCED_NGRAM_AVAILABLE and advanced_ngram and hasattr(advanced_ngram, 'get_stats'):
        try:
            stats = advanced_ngram.get_stats()
            if stats and isinstance(stats, dict):
                logger.info(f"  - N-gram Modeli: {stats.get('bigrams', 0)} bigram, {stats.get('trigrams', 0)} trigram")
        except Exception:
            pass
            
    if CONTEXT_ANALYZER_AVAILABLE:
        logger.info("  - Context Analyzer: AKTIF")
    if ADVANCED_RANKING_AVAILABLE:
        logger.info("  - Advanced Ranking: AKTIF")
    logger.info("  - Real-Time Learning: AKTIF")
    logger.info("=" * 60)
    
    yield
    
    # --- SHUTDOWN ---
    logger.info("ðŸ›‘ Sistem kapatÄ±lÄ±yor...")
    if elasticsearch_predictor.es_client:
        # Sync vs Async client kontrolÃ¼
        try:
            close_res = elasticsearch_predictor.es_client.close()
            # EÄŸer async Ã§alÄ±ÅŸÄ±yorsa await et (coroutine dÃ¶ner)
            if close_res is not None and hasattr(close_res, '__await__'):
                await close_res
        except Exception as e:
            logger.warning(f"ES close warning: {e}")
            
    logger.info("âœ… KapanÄ±ÅŸ tamamlandÄ±")

# ============================================
# KONFIGÃœRASYON
# ============================================

app = FastAPI(
    title="TextHelper ULTIMATE API",
    version="2.1.0",
    description="Hybrid: Transformer AI + Elasticsearch + FastAPI - En iyi otomatik tamamlama sistemi",
    lifespan=lifespan,
    default_response_class=ORJSONResponse
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

if GZipMiddleware:
    app.add_middleware(GZipMiddleware, minimum_size=1000)

# API Key Middleware
API_KEY = os.getenv("API_KEY", "texthelper-secret-key-2024")

async def api_key_middleware(request: Request, call_next):
    # Health check ve docs hariÃ§ kontrol et
    if request.url.path in ["/docs", "/openapi.json", "/api/v1/health", "/health"]:
        return await call_next(request)
        
    api_key = request.headers.get("X-API-Key")
    if api_key != API_KEY:
        return ORJSONResponse(
            status_code=403,
            content={"code": "FORBIDDEN", "message": "Invalid or missing API Key"}
        )
    return await call_next(request)

app.add_middleware(BaseHTTPMiddleware, dispatch=api_key_middleware)

from fastapi.responses import JSONResponse

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger.error(f"Global exception: {exc}", exc_info=True)
    return ORJSONResponse(
        status_code=500,
        content=StandardErrorResponse(
            code="INTERNAL_SERVER_ERROR",
            message="Beklenmeyen sunucu hatasi",
            details={"error": str(exc)}
        ).model_dump()
    )

from typing import List, Optional, Dict, Generic, TypeVar

# ============================================
# MODELLER
# ============================================

class StandardErrorResponse(BaseModel):
    """Standart Hata YanÄ±tÄ± Modeli"""
    code: str
    message: str
    details: Optional[Dict] = None
    timestamp: datetime = datetime.now()

class PredictionRequest(BaseModel):
    text: str
    context_message: Optional[str] = None  # YENÄ°: Ã–nceki mesaj
    max_suggestions: Optional[int] = 80
    use_ai: Optional[bool] = True
    use_search: Optional[bool] = True
    user_id: Optional[str] = "default"

class Suggestion(BaseModel):
    text: str
    type: str
    score: float
    description: str
    source: str

class PredictionResponse(BaseModel):
    suggestions: List[Suggestion]
    corrected_text: Optional[str] = None
    processing_time_ms: float
    sources_used: List[str]

class FeedbackRequest(BaseModel):
    text: str
    selected_suggestion: str
    user_id: str = "default"

# ============================================
# 1. TRANSFORMER MODEL (AI TAHMÄ°NLERÄ°)
# ============================================

class TransformerPredictor:
    """AI tabanlÄ± tahminler iÃ§in Transformer modeli"""
    
    def __init__(self):
        self.model_loaded = False
        self.model = None
        self.tokenizer = None
        self.use_transformer = os.getenv("USE_TRANSFORMER", "false").lower() == "true"
        
    async def load_model(self):
        """Transformer modelini yÃ¼kle"""
        # Ã–NCE: GerÃ§ek transformer modeli kullan (varsa) - HER ZAMAN DENE!
        if REAL_TRANSFORMER_AVAILABLE and transformer_model:
            await transformer_model.load_model()
            self.model_loaded = transformer_model.model_loaded
            if self.model_loaded:
                print("[OK] Gercek Transformer modeli yuklendi")
                return
        
        # Fallback: Pattern-based (sadece gerÃ§ek model yoksa)
        if not self.use_transformer and not self.model_loaded:
            print("[INFO] Transformer kullanimi devre disi (USE_TRANSFORMER=true ile aktif edin)")
            print("[INFO] Gercek Transformer modeli yuklenemedi, pattern-based fallback kullanilacak")
            return
            
        try:
            # Hugging Face transformers
            from transformers import AutoTokenizer, AutoModelForCausalLM
            
            print("[INFO] Transformer modeli yukleniyor...")
            # BERT yerine GPT-2 modeline geÃ§iÅŸ (Text Generation iÃ§in daha uygun)
            model_name = "ytu-ce-cosmos/turkish-gpt2-medium"
            
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModelForCausalLM.from_pretrained(model_name)
            self.model.eval()  # Evaluation mode
            
            self.model_loaded = True
            print("[OK] Transformer modeli hazir")
        except ImportError:
            print("[WARNING] transformers kutuphanesi kurulu degil: pip install transformers torch")
            self.model_loaded = False
        except Exception as e:
            print(f"[WARNING] Transformer modeli yuklenemedi: {e}")
            self.model_loaded = False
    
    async def predict(self, text: str, max_suggestions: int = 5) -> List[Suggestion]:
        """AI ile tahmin yap"""
        # GerÃ§ek transformer modeli kullan (varsa)
        if REAL_TRANSFORMER_AVAILABLE and transformer_model and transformer_model.model_loaded:
            results = await transformer_model.predict(text, max_suggestions)
            return [Suggestion(**r) for r in results]
        
        if not self.model_loaded:
            return self._fallback_predictions(text, max_suggestions)
        
        try:
            import torch
            # GerÃ§ek transformer tahmini
            inputs = self.tokenizer(text, return_tensors="pt", truncation=True, max_length=128)
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_length=inputs['input_ids'].shape[1] + 20,
                    num_return_sequences=max_suggestions,
                    do_sample=True,
                    temperature=0.7,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            
            suggestions = []
            for output in outputs:
                generated_text = self.tokenizer.decode(output, skip_special_tokens=True)
                # Son kelimeyi al
                last_word = generated_text.split()[-1] if generated_text.split() else ""
                
                if last_word and last_word not in [s.text for s in suggestions]:
                    suggestions.append(Suggestion(
                        text=last_word,
                        type="ai_prediction",
                        score=9.5,
                        description="AI tahmini (Transformer)",
                        source="transformer"
                    ))
            
            return suggestions[:max_suggestions]
        except Exception as e:
            print(f"Transformer tahmin hatasÄ±: {e}")
            return self._fallback_predictions(text, max_suggestions)
    
    def _fallback_predictions(self, text: str, max_suggestions: int) -> List[Suggestion]:
        """Fallback: AkÄ±llÄ± pattern matching"""
        suggestions = []
        words = text.split()
        last_word = words[-1].lower() if words else text.lower()
        
        # TÃ¼rkÃ§e pattern'ler
        patterns = {
            'man': ['mantÄ±k', 'mantÄ±klÄ±', 'mantÄ±ksÄ±z', 'mantÄ±ken', 'mantÄ±ksal'],
            'nas': ['nasÄ±l', 'nasÄ±l yardÄ±mcÄ±', 'nasÄ±l olabilirim', 'nasÄ±l yapabilirim'],
            'mer': ['merhaba', 'merhaba size', 'merhaba nasÄ±l', 'merhaba hoÅŸ'],
            'teÅŸ': ['teÅŸekkÃ¼r', 'teÅŸekkÃ¼rler', 'teÅŸekkÃ¼r ederim', 'teÅŸekkÃ¼r ederiz'],
            'yar': ['yardÄ±m', 'yardÄ±mcÄ±', 'yardÄ±mcÄ± olabilirim', 'yardÄ±m etmek'],
            'mÃ¼s': ['mÃ¼ÅŸteri', 'mÃ¼ÅŸteri hizmetleri', 'mÃ¼ÅŸteri desteÄŸi', 'mÃ¼ÅŸteri memnuniyeti'],
            'sip': ['sipariÅŸ', 'sipariÅŸiniz', 'sipariÅŸ takibi', 'sipariÅŸ durumu'],
            'ara': ['ara', 'araba', 'arama', 'aramak', 'arayabilirsiniz'],
            'aÃ§': ['aÃ§Ä±k', 'aÃ§mak', 'aÃ§Ä±klama', 'aÃ§Ä±klamak', 'aÃ§Ä±klayabilirim'],
        }
        
        prefix = last_word[:3] if len(last_word) >= 3 else last_word
        if prefix in patterns:
            for word in patterns[prefix][:max_suggestions]:
                suggestions.append(Suggestion(
                    text=word,
                    type="ai_prediction",
                    score=9.0,
                    description="AI tahmini (Pattern)",
                    source="transformer"
                ))
        
        return suggestions

transformer_predictor = TransformerPredictor()

# ============================================
# 2. ELASTICSEARCH (HIZLI SÃ–ZLÃœK ARAMA)
# ============================================

class ElasticsearchPredictor:
    """Elasticsearch ile hÄ±zlÄ± sÃ¶zlÃ¼k arama"""
    
    def __init__(self):
        self.es_client = None
        self.use_elasticsearch = os.getenv("USE_ELASTICSEARCH", "false").lower() == "true"
        self.local_dictionary = [] # Lazy load
        self._dictionary_loaded = False
        
    def _load_dictionary(self) -> List[str]:
        """Yerel sÃ¶zlÃ¼k yÃ¼kle (Elasticsearch yoksa)"""
        if self._dictionary_loaded:
            return self.local_dictionary
            
        # BÃ¼yÃ¼k TÃ¼rkÃ§e sÃ¶zlÃ¼k
        dictionary_file = os.path.join(os.path.dirname(__file__), "turkish_dictionary.txt")
        
        try:
            if os.path.exists(dictionary_file):
                print(f"[INFO] SÃ¶zlÃ¼k yÃ¼kleniyor... ({dictionary_file})")
                with open(dictionary_file, 'r', encoding='utf-8') as f:
                    # Generator kullanarak belleÄŸi koru (ama liste lazÄ±m ise mecburen)
                    # Sadece ilk 500k kelimeyi alalim memory korumak icin
                    lines = []
                    count = 0
                    for line in f:
                        if line.strip():
                            lines.append(line.strip())
                            count += 1
                            if count >= 500000: # Limit memory usage
                                break
                    
                self._dictionary_loaded = True
                print(f"[OK] SÃ¶zlÃ¼k yÃ¼klendi ({len(lines)} kelime)")
                return lines
        except MemoryError:
            print("[WARNING] Yetersiz bellek - BÃ¼yÃ¼k sÃ¶zlÃ¼k yÃ¼klenemedi. VarsayÄ±lan kÃ¼Ã§Ã¼k sÃ¶zlÃ¼k kullanÄ±lacak.")
        except Exception as e:
            print(f"[WARNING] SÃ¶zlÃ¼k yÃ¼kleme hatasÄ±: {e}")
        
        # VarsayÄ±lan sÃ¶zlÃ¼k (Fallback)
        self._dictionary_loaded = True
        return [
            # MantÄ±k kelimeleri
            'mantÄ±k', 'mantÄ±klÄ±', 'mantÄ±ksÄ±z', 'mantÄ±ken', 'mantÄ±ksal', 'mantÄ±kÃ§a',
            # Merhaba ve selamlaÅŸma
            'merhaba', 'merhaba size', 'merhaba nasÄ±l', 'merhaba hoÅŸ', 'selam',
            'selamlar', 'selamun aleykÃ¼m', 'hoÅŸ geldiniz', 'hoÅŸ geldin',
            # TeÅŸekkÃ¼r
            'teÅŸekkÃ¼r', 'teÅŸekkÃ¼rler', 'teÅŸekkÃ¼r ederim', 'teÅŸekkÃ¼r ederiz',
            'teÅŸekkÃ¼r ediyorum', 'teÅŸekkÃ¼r ediyoruz', 'saÄŸolun', 'saÄŸ olun',
            # YardÄ±m
            'yardÄ±m', 'yardÄ±mcÄ±', 'yardÄ±mcÄ± olabilirim', 'yardÄ±m etmek',
            'yardÄ±mcÄ± olmak', 'destek', 'destek olmak', 'destek vermek',
            # MÃ¼ÅŸteri
            'mÃ¼ÅŸteri', 'mÃ¼ÅŸteri hizmetleri', 'mÃ¼ÅŸteri desteÄŸi', 'mÃ¼ÅŸteri memnuniyeti',
            'mÃ¼ÅŸteri temsilcisi', 'mÃ¼ÅŸteri danÄ±ÅŸmanÄ±',
            # SipariÅŸ
            'sipariÅŸ', 'sipariÅŸiniz', 'sipariÅŸ takibi', 'sipariÅŸ durumu',
            'sipariÅŸ vermek', 'sipariÅŸ almak',
            # Ara
            'ara', 'araba', 'arama', 'aramak', 'arayabilirsiniz', 'arayabilirim',
            'arama yapmak', 'arama sonuÃ§larÄ±',
            # AÃ§
            'aÃ§Ä±k', 'aÃ§mak', 'aÃ§Ä±klama', 'aÃ§Ä±klamak', 'aÃ§Ä±klayabilirim',
            'aÃ§Ä±klayabilir misiniz', 'aÃ§Ä±klayabilir misin',
            # NasÄ±l
            'nasÄ±l', 'nasÄ±l yardÄ±mcÄ±', 'nasÄ±l olabilirim', 'nasÄ±l yapabilirim',
            'nasÄ±l yapÄ±lÄ±r', 'nasÄ±l kullanÄ±lÄ±r',
            # DiÄŸer yaygÄ±n kelimeler
            'iyi', 'kÃ¶tÃ¼', 'gÃ¼zel', 'bÃ¼yÃ¼k', 'kÃ¼Ã§Ã¼k', 'yeni', 'eski',
            'yapmak', 'etmek', 'olmak', 'gelmek', 'gitmek', 'vermek', 'almak',
            'sorun', 'problem', 'Ã§Ã¶zÃ¼m', 'bilgi', 'detay', 'fiyat', 'Ã¼cret',
            'Ã¼rÃ¼n', 'hizmet', 'kargo', 'teslimat', 'iade', 'deÄŸiÅŸim',
        ]
    
    async def connect_elasticsearch(self):
        """Elasticsearch'e baÄŸlan"""
        # ES Manager kullan (varsa)
        if ES_MANAGER_AVAILABLE and es_manager:
            try:
                if hasattr(es_manager, 'connect'):
                    await es_manager.connect()
                if hasattr(es_manager, 'available') and es_manager.available:
                    if hasattr(es_manager, 'es_client'):
                        self.es_client = es_manager.es_client
                    print("[OK] Elasticsearch Manager ile baglanti kuruldu")
                    return
            except Exception as e:
                print(f"[WARNING] ES manager connect hatasi: {e}")
        
        # Fallback: Direkt baÄŸlantÄ± (USE_ELASTICSEARCH kontrolÃ¼ kaldÄ±rÄ±ldÄ± - her zaman dene)
        try:
            from elasticsearch import Elasticsearch
            
            es_host = os.getenv("ELASTICSEARCH_HOST", "localhost:9200")
            # URL formatÄ±nÄ± dÃ¼zelt (http:// ekle)
            if not es_host.startswith("http://") and not es_host.startswith("https://"):
                es_host = f"http://{es_host}"
            
            # Elasticsearch client oluÅŸtur (timeout ve retry ile)
            self.es_client = Elasticsearch(
                [es_host],
                request_timeout=10,
                max_retries=2,
                retry_on_timeout=True
            )
            
            # BaÄŸlantÄ± testi (ping)
            try:
                if self.es_client.ping():
                    print(f"[OK] Elasticsearch baglantisi kuruldu: {es_host}")
                else:
                    print("[WARNING] Elasticsearch'e baglanilamadi (ping basarisiz), yerel sozluk kullanilacak")
                    print("[INFO] Elasticsearch calisiyor mu kontrol edin: http://localhost:9200")
                    print("[INFO] Elasticsearch baslatmak icin: DOCKER_BASLAT.bat")
                    self.es_client = None
            except Exception as ping_error:
                # Normal durum - yerel sÃ¶zlÃ¼k kullanÄ±lacak (Elasticsearch opsiyonel)
                print(f"[INFO] Elasticsearch kullanilamiyor, yerel sozluk kullanilacak (normal)")
                print(f"[INFO] Elasticsearch'i aktif etmek icin: DOCKER_BASLAT.bat")
                self.es_client = None
        except ImportError:
            print("[WARNING] elasticsearch kutuphanesi kurulu degil: pip install elasticsearch")
            self.es_client = None
        except Exception as e:
            error_msg = str(e)
            # Normal durum - yerel sÃ¶zlÃ¼k kullanÄ±lacak (Elasticsearch opsiyonel)
            print(f"[INFO] Elasticsearch kullanilamiyor, yerel sozluk kullanilacak (normal)")
            print(f"[INFO] Elasticsearch'i aktif etmek icin: DOCKER_BASLAT.bat")
            self.es_client = None
    
    async def search(self, prefix: str, max_results: int = 50) -> List[Suggestion]:  # ArtÄ±rÄ±ldÄ±: 10 -> 50
        """Elasticsearch'te ara (veya yerel sÃ¶zlÃ¼kte)"""
        if self.es_client:
            return await self._elasticsearch_search(prefix, max_results)
        else:
            return await self._local_search(prefix, max_results)
    
    async def _elasticsearch_search(self, prefix: str, max_results: int) -> List[Suggestion]:
        """Elasticsearch ile ara"""
        # ES Manager kullan (varsa)
        if ES_MANAGER_AVAILABLE and es_manager and hasattr(es_manager, 'available') and es_manager.available:
            try:
                if hasattr(es_manager, 'search'):
                    results = await es_manager.search(prefix, max_results)
                    if results and isinstance(results, list):
                        return [Suggestion(**r) for r in results if isinstance(r, dict)]
            except Exception as e:
                print(f"[WARNING] ES manager search hatasi: {e}")
        
        # Fallback: Direkt ES query
        if not self.es_client:
            return await self._local_search(prefix, max_results)
        
        try:
            query = {
                "suggest": {
                    "word-suggest": {
                        "prefix": prefix.lower(),
                        "completion": {
                            "field": "word_suggest",
                            "size": max_results
                        }
                    }
                }
            }
            
            response = self.es_client.search(index="turkish_words", body=query)
            suggestions = []
            
            for option in response.get('suggest', {}).get('word-suggest', [{}])[0].get('options', []):
                suggestions.append(Suggestion(
                    text=option['text'],
                    type="dictionary",
                    score=8.0 + (option.get('score', 0) / 100),
                    description="SÃ¶zlÃ¼k (Elasticsearch)",
                    source="elasticsearch"
                ))
            
            return suggestions
        except Exception as e:
            print(f"Elasticsearch arama hatasÄ±: {e}")
            return await self._local_search(prefix, max_results)
    
    async def _local_search(self, prefix: str, max_results: int) -> List[Suggestion]:
        """Yerel sÃ¶zlÃ¼kte ara - WHATSAPP BENZERÄ° (her karakter iÃ§in anlÄ±k Ã¶neri)"""
        suggestions = []
        prefix_lower = prefix.lower().strip()
        
        # BoÅŸ prefix kontrolÃ¼
        if not prefix_lower:
            return suggestions
            
        # Lazy load check
        if not self.local_dictionary and not self._dictionary_loaded:
             self.local_dictionary = self._load_dictionary()
        
        # WHATSAPP BENZERÄ°: BÃ¼yÃ¼k sÃ¶zlÃ¼k kullan (varsa) - Ã–NCELÄ°K!
        if LARGE_DICT_AVAILABLE and large_dictionary:
            try:
                results = large_dictionary.search(prefix_lower, max_results)
                if results:
                    for result in results:
                        suggestions.append(Suggestion(
                            text=result['word'],
                            type="dictionary",
                            score=result.get('score', 8.0),
                            description=f"SÃ¶zlÃ¼k (frekans: {result.get('frequency', 0)})",
                            source="large_dictionary"
                        ))
                    return suggestions
            except Exception as e:
                print(f"Large dictionary search hatasÄ±: {e}")
                # Fallback'e geÃ§
        
        # WHATSAPP BENZERÄ°: VarsayÄ±lan sÃ¶zlÃ¼k (fallback - hÄ±zlÄ±)
        for word in self.local_dictionary:
            word_lower = word.lower()
            
            # WHATSAPP BENZERÄ°: Prefix match - her karakter iÃ§in Ã¶neri
            if len(prefix_lower) >= 1 and word_lower.startswith(prefix_lower) and word_lower != prefix_lower:
                # WHATSAPP BENZERÄ°: Skorlama - prefix uzunluÄŸu Ã¶nemli
                if len(prefix_lower) == 1:
                    score = 9.5 - (len(word_lower) * 0.02)  # KÄ±sa kelimeler Ã¶ncelikli
                elif len(prefix_lower) == 2:
                    score = 9.0 - (len(word_lower) * 0.01)  # Ä°ki harf
                else:
                    score = (len(prefix_lower) / len(word_lower)) * 8.5  # Ã‡ok harf
                
                suggestions.append(Suggestion(
                    text=word,
                    type="dictionary",
                    score=score,
                    description="SÃ¶zlÃ¼k",
                    source="local_dictionary"
                ))
                
                # WHATSAPP BENZERÄ°: Yeterli Ã¶neri bulunduysa dur (hÄ±zlÄ± yanÄ±t)
                if len(suggestions) >= max_results * 2:
                    break
        
        # WHATSAPP BENZERÄ°: Skora gÃ¶re sÄ±rala (en yÃ¼ksek skorlu Ã¶neriler Ã¶nce)
        suggestions.sort(key=lambda x: x.score, reverse=True)
        return suggestions[:max_results]

elasticsearch_predictor = ElasticsearchPredictor()

# ============================================
# 3. YAZIM DÃœZELTME
# ============================================

class SpellChecker:
    """YazÄ±m dÃ¼zeltme - Lazy loading ile bellek hatasÄ± Ã¶nleme"""
    
    def __init__(self):
        self.speller = None
        self.available = False
        self._initialized = False
    
    def _initialize(self):
        """Lazy initialization - sadece gerektiÄŸinde yÃ¼kle"""
        if self._initialized:
            return
        
        self._initialized = True
        
        try:
            from autocorrect import Speller
            # TÃ¼rkÃ§e model yÃ¼klemeyi dene
            try:
                self.speller = Speller(lang='tr')
                self.available = True
                print("[OK] Yazim duzeltme aktif (autocorrect)")
            except MemoryError:
                print("[WARNING] autocorrect bellek hatasi - yazim duzeltme devre disi")
                self.available = False
            except Exception as e:
                print(f"[WARNING] autocorrect yukleme hatasi: {e}")
                self.available = False
        except ImportError:
            self.available = False
            print("[WARNING] autocorrect kurulu degil: pip install autocorrect")
    
    async def check(self, word: str) -> Optional[str]:
        """YazÄ±m hatasÄ±nÄ± dÃ¼zelt"""
        # Lazy initialization
        if not self._initialized:
            self._initialize()
        
        if not self.available or not self.speller or len(word) <= 3:
            return None
        
        try:
            corrected = self.speller(word)
            return corrected if corrected != word else None
        except MemoryError:
            # Bellek hatasÄ± durumunda devre dÄ±ÅŸÄ± bÄ±rak
            self.available = False
            return None
        except Exception:
            return None

spell_checker = SpellChecker()

# ============================================
# 4. HYBRID ORCHESTRATOR (BÄ°RLEÅžTÄ°RME)
# ============================================

class HybridOrchestrator:
    """Transformer ve Elasticsearch sonuÃ§larÄ±nÄ± birleÅŸtir"""
    
    # Backend-side debouncing (50ms cooldown per user)
    _last_request = {}
    _DEBOUNCE_MS = 50  # 50ms
    
    # LRU Cache for search results (max 500 entries)
    from functools import lru_cache
    
    @staticmethod
    @lru_cache(maxsize=500)
    def _cached_search(prefix: str, max_results: int) -> tuple:
        """Cached search results (returns tuple for hashability)"""
        if LARGE_DICT_AVAILABLE and large_dictionary:
            results = large_dictionary.search(prefix, max_results)
            return tuple(results) if results else ()
        return ()
    
    async def predict(
        self,
        text: str,
        context_message: str = None,  # YENÄ°
        max_suggestions: int = 50,
        use_ai: bool = True,
        use_search: bool = True,
        user_id: str = "default"
    ) -> PredictionResponse:
        """Hybrid tahmin yap"""
        import time
        
        # Backend Debouncing: Skip if request too fast (CPU optimization)
        now = time.time() * 1000
        last = self._last_request.get(user_id, 0)
        if now - last < self._DEBOUNCE_MS:
            # Return empty response for too-fast requests
            return PredictionResponse(
                suggestions=[],
                processing_time_ms=0,
                sources_used=["debounced"]
            )
        self._last_request[user_id] = now
        
        start_time = datetime.now()
        sources_used = []
        all_suggestions = []
        
        # 0. CONTEXTUAL REPLIES (En Ãœst Ã–ncelik - EÄŸer input boÅŸsa veya kÄ±saysa)
        if context_message and (not text or len(text) < 3):
            # Basit kural tabanlÄ± Replies (Ä°leride AI kullanÄ±labilir)
            replies = []
            cm_lower = context_message.lower()
            
            if "nasÄ±lsÄ±n" in cm_lower or "naber" in cm_lower:
                replies = ["Ä°yiyim, teÅŸekkÃ¼rler", "TeÅŸekkÃ¼rler, siz nasÄ±lsÄ±nÄ±z?", "Her ÅŸey yolunda"]
            elif "yardÄ±m" in cm_lower:
                replies = ["NasÄ±l yardÄ±mcÄ± olabilirim?", "Sorun nedir?", "Buyurun, dinliyorum"]
            elif "sipariÅŸ" in cm_lower:
                replies = ["SipariÅŸ numaranÄ±z nedir?", "Hemen kontrol ediyorum"]
            elif "merhaba" in cm_lower or "selam" in cm_lower:
                replies = ["Merhabalar", "Selamlar", "HoÅŸ geldiniz"]
                
            if replies:
                for reply in replies:
                    all_suggestions.append(Suggestion(
                        text=reply,
                        type="smart_reply",
                        score=50.0, # Ã‡ok yÃ¼ksek skor
                        description="AkÄ±llÄ± YanÄ±t",
                        source="contextual_reply"
                    ))
                
                # EÄŸer yanÄ±t bulduysak ve text boÅŸsa, direkt dÃ¶n
                if not text and all_suggestions:
                     end_time = datetime.now()
                     processing_time = (end_time - start_time).total_seconds() * 1000
                     return PredictionResponse(
                        suggestions=all_suggestions,
                        processing_time_ms=processing_time,
                        sources_used=["contextual_reply"]
                    )
        
        # WHATSAPP BENZERÄ°: Cache tamamen devre dÄ±ÅŸÄ± - her karakter iÃ§in yeni Ã¶neri!
        # WhatsApp iPhone gibi Ã§alÄ±ÅŸmasÄ± iÃ§in cache kullanma
        cache_key = None
        # Cache devre dÄ±ÅŸÄ± - her karakter iÃ§in anlÄ±k Ã¶neri
        # if REDIS_AVAILABLE and cache:
        #     try:
        #         cache_key = cache.generate_key("predict", text, max_suggestions, use_ai, use_search)
        #         cached_result = cache.get(cache_key)
        #         if cached_result:
        #             return PredictionResponse(**cached_result)
        #     except Exception as e:
        #         print(f"[WARNING] Cache kontrol hatasi: {e}")
        
        # HYBRID: Context analizi (ARKA PLANDA - hÄ±zlÄ± Ã¶nerilerden sonra)
        # WhatsApp/iPhone: Ã–nce hÄ±zlÄ± Ã¶neriler, sonra context-aware Ã¶neriler
        context = None
        # if CONTEXT_ANALYZER_AVAILABLE and context_analyzer:
        #     # Context analizi hafif, ekle (arka planda Ã§alÄ±ÅŸÄ±r)
        #     try:
        #         context = context_analyzer.analyze(text)
        #     except Exception:
        #         context = None
        
        # YENI: GeliÅŸmiÅŸ Context Analizi (Ã–ncelikli)
        if ADVANCED_CONTEXT_AVAILABLE and advanced_context_completer:
             try:
                 # AkÄ±llÄ± yanÄ±tlarÄ± ve context Ã¶nerilerini ekle
                 smart_responses = advanced_context_completer.generate_smart_responses(text)
                 if smart_responses:
                     all_suggestions.extend(smart_responses)
                 
                 context_suggestions = advanced_context_completer.complete_with_full_context(text, max_suggestions)
                 if context_suggestions:
                     all_suggestions.extend(context_suggestions)
             except Exception as e:
                 print(f"[WARNING] Advanced Context hatasi: {e}")
        
        # YENI: ML Learning (KiÅŸiselleÅŸtirilmiÅŸ Ã–neriler)
        if ML_LEARNING_AVAILABLE and ml_learning:
            try:
                # KullanÄ±cÄ±ya Ã¶zel sÄ±ralama
                all_suggestions = ml_learning.get_personalized_suggestions(user_id, text, all_suggestions)
            except Exception as e:
                print(f"[WARNING] ML Learning hatasi: {e}")

        # Paralel olarak her kaynaktan al
        tasks = []
        
        # 1. HYBRID: AI Tahminleri (Transformer) - ARKA PLANDA (sadece heavy features aktifse)
        # WhatsApp/iPhone: Transformer kullanmaz ama biz hybrid yaklaÅŸÄ±mla ekleyebiliriz
        # Ã–nce hÄ±zlÄ± Ã¶neriler gÃ¶sterilir, sonra Transformer Ã¶nerileri gelir (arka planda)
        use_transformer = os.getenv("USE_TRANSFORMER", "false").lower() == "true"
        enable_heavy_features = os.getenv("ENABLE_HEAVY_FEATURES", "false").lower() == "true"
        
        if use_ai and use_transformer and enable_heavy_features:
            # Transformer: Arka planda Ã§alÄ±ÅŸÄ±r (smart_tasks'a eklenir - akÄ±llÄ± Ã¶neriler)
            tasks.append(self._get_ai_predictions(text, max_suggestions, sources_used))
        
        # 2. WHATSAPP BENZERÄ°: SÃ¶zlÃ¼k Arama - Son kelimeye odaklan, her karakter iÃ§in gÃ¼ncelle!
        # WhatsApp iPhone gibi: "a" -> "ak" -> "akÄ±" -> "akÄ±l" her adÄ±mda gÃ¼ncelleniyor
        if use_search:
            words = text.split()
            last_word = words[-1] if words else text
            last_word = last_word.strip()
            
            # ALKALI Ã–NERÄ°LER Ä°Ã‡Ä°N: Her karakter iÃ§in Ã¶neri ver (>= 1) - GARANTÄ°LÄ°!
            if len(last_word) >= 1:
                # Ã–ncelik: Trie Index (en hÄ±zlÄ± - WhatsApp benzeri anlÄ±k Ã¶neri)
                if TRIE_AVAILABLE and trie_index and hasattr(trie_index, 'word_count') and trie_index.word_count > 0:
                    tasks.append(self._get_trie_predictions(last_word, max_suggestions * 6, sources_used))
                
                # Her zaman local search (fallback - GARANTÄ°LÄ°!)
                tasks.append(self._get_search_predictions(last_word, max_suggestions * 6, sources_used))
                
                # KELÄ°ME SAYISINI ARTIRMAK Ä°Ã‡Ä°N: Large dictionary'den direkt arama (tÃ¼m uzunluklar iÃ§in)
                if LARGE_DICT_AVAILABLE and large_dictionary:
                    tasks.append(self._get_direct_large_dict_predictions(last_word, max_suggestions * 5, sources_used))
                
                # YENI: Medium Dictionary (Reliable & Fast Fallback)
                if MEDIUM_DICT_AVAILABLE and medium_dictionary:
                    # Senkron olduÄŸu iÃ§in direkt Ã§alÄ±ÅŸtÄ±rabiliriz veya async wrapper yapabiliriz
                    # HÄ±zlÄ± olduÄŸu iÃ§in direkt ekleyelim
                    try:
                        md_results = medium_dictionary.search(last_word, max_suggestions)
                        if md_results:
                            md_suggestions = [Suggestion(
                                text=res['word'],
                                type='dictionary',
                                score=res['score'],
                                description='SÃ¶zlÃ¼k (Medium)',
                                source='medium_dictionary'
                            ) for res in md_results]
                            all_suggestions.extend(md_suggestions)
                    except Exception as e:
                        print(f"[WARNING] Medium dictionary hatasi: {e}")
        
        # 3. N-Gram Tahminleri (Hafif - aktif)
        if ADVANCED_NGRAM_AVAILABLE and advanced_ngram:
            tasks.append(self._get_ngram_predictions(text, max_suggestions * 2, sources_used))
        
        # 4. Phrase Completion (Hafif - aktif)
        if PHRASE_COMPLETION_AVAILABLE and phrase_completer:
            tasks.append(self._get_phrase_predictions(text, max_suggestions * 2, sources_used))
        
        # 5. Domain-Specific (mÃ¼ÅŸteri hizmeti odaklÄ± - HER ZAMAN)
        if DOMAIN_DICT_AVAILABLE and domain_manager:
            tasks.append(self._get_domain_predictions(text, max_suggestions * 2, sources_used))
        
        enable_heavy_features = os.getenv("ENABLE_HEAVY_FEATURES", "false").lower() == "true"
        
        # 6. Emoji Suggestions (Hafif - aktif)
        if EMOJI_AVAILABLE and emoji_suggester:
            tasks.append(self._get_emoji_predictions(text, max_suggestions * 2, sources_used))
        
        # 7. Smart Templates (AÄŸÄ±r - opsiyonel)
        if enable_heavy_features and SMART_TEMPLATES_AVAILABLE and smart_template_manager:
            tasks.append(self._get_template_predictions(text, max_suggestions * 2, sources_used))
        
        # HYBRID YAKLAÅžIM: Ä°ki aÅŸamalÄ± Ã¶neri sistemi
        # AÅžAMA 1: HÄ±zlÄ± Ã¶neriler (Trie + Large Dict) - milisaniyelik yanÄ±t
        # AÅžAMA 2: AkÄ±llÄ± Ã¶neriler (N-gram, Phrase, Context) - arka planda
        
        # HÄ±zlÄ± task'lar (Trie, Large Dict) - Ã¶nce Ã§alÄ±ÅŸtÄ±r
        fast_tasks = []
        smart_tasks = []
        
        for task in tasks:
            # Task'Ä±n kaynaÄŸÄ±nÄ± kontrol et (basit kontrol)
            task_str = str(task)
            if 'trie' in task_str.lower() or 'large_dict' in task_str.lower() or 'direct_large_dict' in task_str.lower():
                fast_tasks.append(task)
            else:
                smart_tasks.append(task)
        
        # AÅžAMA 1: HÄ±zlÄ± Ã¶neriler (100ms timeout - milisaniyelik yanÄ±t)
        async def with_fast_timeout(task):
            try:
                return await asyncio.wait_for(task, timeout=0.1)  # 100ms
            except (asyncio.TimeoutError, Exception):
                return []
        
        fast_results = []
        if fast_tasks:
            fast_results = await asyncio.gather(*[with_fast_timeout(task) for task in fast_tasks], return_exceptions=True)
        
        # AÅžAMA 2: AkÄ±llÄ± Ã¶neriler (500ms timeout - arka planda, hÄ±zlÄ± Ã¶nerilerden sonra)
        async def with_smart_timeout(task):
            try:
                return await asyncio.wait_for(task, timeout=0.5)  # 500ms
            except (asyncio.TimeoutError, Exception):
                return []
        
        smart_results = []
        if smart_tasks:
            # Arka planda Ã§alÄ±ÅŸtÄ±r (hÄ±zlÄ± Ã¶neriler gÃ¶sterildikten sonra)
            smart_results = await asyncio.gather(*[with_smart_timeout(task) for task in smart_tasks], return_exceptions=True)
        
        # SonuÃ§larÄ± birleÅŸtir (hÄ±zlÄ± Ã¶neriler Ã¶nce, akÄ±llÄ± Ã¶neriler sonra)
        results = fast_results + smart_results
        
        # SonuÃ§larÄ± birleÅŸtir
        for result in results:
            if isinstance(result, Exception):
                print(f"[WARNING] Task hatasi: {result}")
                continue
            if isinstance(result, list):
                all_suggestions.extend(result)
        
        # WhatsApp/iPhone benzeri: 1-2 karakter iÃ§in Ã¶ncelikli Ã¶neriler (mâ†’merhaba, nâ†’nasÄ±l, ...)
        if SMART_COMPLETIONS_AVAILABLE and get_smart_completions and use_search and text:
            _words = text.split()
            _lw = (_words[-1] if _words else text).strip()
            if 1 <= len(_lw) <= 4:
                comps = get_smart_completions(_lw, max_suggestions * 3)
                for d in comps:
                    all_suggestions.insert(0, Suggestion(
                        text=d["word"],
                        type=d.get("type", "smart_completion"),
                        score=d.get("score", 14.0),
                        description=d.get("description", "Ã–neri (Ã¶ncelikli)"),
                        source=d.get("source", "smart_completions")
                    ))
                if comps and "smart_completions" not in sources_used:
                    sources_used.append("smart_completions")
        
        # 4-9. HYBRID: AkÄ±llÄ± Ã¶zellikler (ARKA PLANDA - hÄ±zlÄ± Ã¶nerilerden sonra)
        # WhatsApp/iPhone: Ã–nce hÄ±zlÄ± Ã¶neriler gÃ¶sterilir, sonra daha akÄ±llÄ± Ã¶neriler gelir
        corrected_text = None
        
        # ALKALI Ã–NERÄ°LER: Context-aware filtreleme (HER ZAMAN AKTÄ°F - alakalÄ± Ã¶neriler iÃ§in)
        if CONTEXT_ANALYZER_AVAILABLE and context_analyzer and context and all_suggestions:
            try:
                all_suggestions_dict = [{'text': s.text, 'score': s.score, 'type': s.type, 'source': s.source, 'description': s.description} for s in all_suggestions]
                filtered = context_analyzer.filter_suggestions_by_context(all_suggestions_dict, context)
                if filtered and isinstance(filtered, list) and len(filtered) > 0:
                    # ALKALI Ã–NERÄ°LER Ä°Ã‡Ä°N: Context'e uygun Ã¶nerileri Ã¶nceliklendir ve skorla
                    context_suggestions = [Suggestion(**s) for s in filtered if isinstance(s, dict)]
                    # Context Ã¶nerilerine bonus skor ver (alkalÄ± Ã¶neriler iÃ§in)
                    for ctx_sug in context_suggestions:
                        ctx_sug.score += 2.0  # Context bonus (alkalÄ± Ã¶neriler iÃ§in)
                    # Context Ã¶nerilerini baÅŸa ekle (Ã¶ncelikli)
                    all_suggestions = context_suggestions + [s for s in all_suggestions if s not in context_suggestions]
            except Exception as e:
                pass  # Hata olursa devam et
        
        # Fuzzy Matching (sadece uzun kelimeler iÃ§in - hafif)
        enable_heavy_features = os.getenv("ENABLE_HEAVY_FEATURES", "false").lower() == "true"
        if text:
            words = text.split()
            if words:
                last_word = words[-1]
                # Sadece uzun kelimeler iÃ§in fuzzy matching (hÄ±zlÄ±)
                if len(last_word) > 4 and ADVANCED_FUZZY_AVAILABLE and advanced_fuzzy and LARGE_DICT_AVAILABLE and large_dictionary:
                    try:
                        candidates = large_dictionary.words[:200]  # Ã‡ok az aday (hÄ±zlÄ±)
                        fuzzy_matches = advanced_fuzzy.match(last_word, candidates, max_results=1)
                        if fuzzy_matches and fuzzy_matches[0]['confidence'] > 0.8:
                            corrected = fuzzy_matches[0]['word']
                            corrected_text = ' '.join(words[:-1] + [corrected])
                    except Exception:
                        pass
        
        # Advanced Context Completion (hafif - arka planda)
        if ADVANCED_CONTEXT_AVAILABLE and advanced_context_completer and all_suggestions:
            try:
                # Timeout ile (Ã§ok hÄ±zlÄ±)
                context_suggestions = await asyncio.wait_for(
                    asyncio.to_thread(advanced_context_completer.complete_with_full_context, text, max_suggestions),
                    timeout=0.3  # 300ms timeout
                )
                if context_suggestions:
                    for ctx_sug in context_suggestions[:5]:  # Sadece ilk 5 (hÄ±zlÄ±)
                        if isinstance(ctx_sug, dict):
                            all_suggestions.append(Suggestion(
                                text=ctx_sug.get('text', ''),
                                type=ctx_sug.get('type', 'phrase'),
                                score=ctx_sug.get('score', 0.0),
                                description=ctx_sug.get('description', ''),
                                source=ctx_sug.get('source', 'advanced_context')
                            ))
            except (asyncio.TimeoutError, Exception):
                pass  # Timeout olursa devam et
        
        # 9.1. ALKALI Ã–NERÄ°LER: Relevance Filter (HER ZAMAN AKTÄ°F - alakasÄ±z Ã¶nerileri filtrele)
        # YazÄ±lan ile alakalÄ± Ã¶neriler iÃ§in relevance filter her zaman aktif
        words = text.split()
        last_word = words[-1] if words else text
        
        # ALKALI Ã–NERÄ°LER Ä°Ã‡Ä°N: Her zaman filtrele (sadece Ã§ok fazla Ã¶neri deÄŸil)
        # Minimum 2 karakter ve en az 5 Ã¶neri varsa filtrele
        should_filter = len(all_suggestions) > 5 and len(last_word) >= 2
        
        if RELEVANCE_FILTER_AVAILABLE and relevance_filter and all_suggestions and should_filter:
            try:
                suggestions_dict = [
                    {
                        'text': s.text,
                        'score': s.score,
                        'type': s.type,
                        'source': s.source,
                        'description': s.description,
                        'frequency': getattr(s, 'frequency', 1)
                    }
                    for s in all_suggestions
                ]
                # ALKALI Ã–NERÄ°LER Ä°Ã‡Ä°N: Relevance filter (alkalasÄ±z Ã¶nerileri filtrele)
                filtered = relevance_filter.filter_irrelevant(suggestions_dict, text, max_suggestions * 5)
                filtered = relevance_filter.remove_duplicates(filtered)
                
                if filtered and isinstance(filtered, list) and len(filtered) > 0:
                    all_suggestions = [Suggestion(**s) for s in filtered if isinstance(s, dict)]
            except Exception:
                pass  # Hata olursa devam et
        
        # 9.2. HYBRID: ML Ranking (ARKA PLANDA - sadece heavy features aktifse)
        # WhatsApp/iPhone: ML ranking kullanÄ±r ama arka planda
        enable_heavy_features = os.getenv("ENABLE_HEAVY_FEATURES", "false").lower() == "true"
        if enable_heavy_features and ML_RANKING_AVAILABLE and ml_ranking and all_suggestions:
            try:
                context_dict = {'text': text, 'domain': 'general'}
                suggestions_dict = [
                    {
                        'text': s.text,
                        'score': s.score,
                        'type': s.type,
                        'source': s.source,
                        'frequency': getattr(s, 'frequency', 1),
                        'context_match': True,
                        'domain_match': True,
                        'grammar_match': False,
                        'semantic_score': 0.5
                    }
                    for s in all_suggestions
                ]
                ranked = ml_ranking.rank_suggestions(suggestions_dict, context_dict, user_id)
                
                if ranked and isinstance(ranked, list):
                    all_suggestions = [Suggestion(**s) for s in ranked if isinstance(s, dict)]
            except Exception as e:
                print(f"[WARNING] ML ranking hatasi: {e}")
        
        # 9.3. YazÄ±lan prefix'in kendisini Ã¶neri olarak gÃ¶sterme ("mer" -> "mer" Ã§Ä±kmaz)
        _parts = text.split()
        _lw = (_parts[-1] if _parts else text).strip().lower()
        if _lw:
            all_suggestions = [s for s in all_suggestions if s.text.strip().lower() != _lw]
        
        # 9.4. SonuÃ§larÄ± birleÅŸtir ve sÄ±rala
        unique_suggestions = self._merge_and_rank(all_suggestions, max_suggestions)
        
        # 9.5. WHATSAPP BENZERÄ°: EÄžER HÄ°Ã‡ Ã–NERÄ° YOKSA, ZORUNLU Ã–NERÄ° VER! (GARANTÄ°LÄ° FALLBACK)
        if not unique_suggestions and len(text.strip()) >= 1:
            words = text.split()
            last_word = words[-1] if words else text
            last_word = last_word.strip()
            
            if len(last_word) >= 1:
                try:
                    # WHATSAPP BENZERÄ°: 3 katmanlÄ± fallback (garantili Ã¶neri)
                    # 1. Direkt local search yap (bypass tÃ¼m filtreler)
                    fallback_suggestions = await elasticsearch_predictor._local_search(last_word, max_suggestions * 5)
                    
                    # 2. EÄŸer hala yoksa, large dictionary'den direkt ara
                    if not fallback_suggestions and LARGE_DICT_AVAILABLE and large_dictionary:
                        try:
                            results = large_dictionary.search(last_word.lower(), max_suggestions * 5)
                            if results:
                                for result in results:
                                    fallback_suggestions.append(Suggestion(
                                        text=result['word'],
                                        type="dictionary",
                                        score=result.get('score', 8.0),
                                        description=f"SÃ¶zlÃ¼k (frekans: {result.get('frequency', 0)})",
                                        source="large_dictionary_fallback"
                                    ))
                        except Exception as e:
                            print(f"[WARNING] Large dict fallback hatasi: {e}")
                    
                    # 3. EÄŸer hala yoksa, varsayÄ±lan sÃ¶zlÃ¼kten ara
                    if not fallback_suggestions:
                        for word in elasticsearch_predictor.local_dictionary[:max_suggestions * 5]:
                            word_lower = word.lower()
                            if word_lower.startswith(last_word.lower()) and word_lower != last_word.lower():
                                fallback_suggestions.append(Suggestion(
                                    text=word,
                                    type="dictionary",
                                    score=8.0,
                                    description="SÃ¶zlÃ¼k (varsayÄ±lan)",
                                    source="default_dictionary"
                                ))
                                if len(fallback_suggestions) >= max_suggestions:
                                    break
                    
                    if fallback_suggestions:
                        unique_suggestions = fallback_suggestions
                        if 'local_dictionary' not in sources_used:
                            sources_used.append('local_dictionary')
                except Exception as e:
                    print(f"[ERROR] Zorunlu arama hatasi: {e}")
                    import traceback
                    traceback.print_exc()
        
        # 10. GeliÅŸmiÅŸ Ranking (final sÄ±ralama - YENÄ°!)
        if ADVANCED_RANKING_AVAILABLE and advanced_ranking and unique_suggestions:
            try:
                suggestions_dict = []
                for s in unique_suggestions:
                    if isinstance(s, dict):
                         suggestions_dict.append(s)
                    else:
                         suggestions_dict.append({
                            'text': getattr(s, 'text', ''),
                            'score': getattr(s, 'score', 0.0),
                            'type': getattr(s, 'type', 'unknown'),
                            'source': getattr(s, 'source', 'unknown'),
                            'description': getattr(s, 'description', '')
                        })
                
                ranked = advanced_ranking.rank_suggestions(suggestions_dict, context, user_id, text)
                if ranked and isinstance(ranked, list):
                    unique_suggestions = [Suggestion(**s) for s in ranked[:max_suggestions] if isinstance(s, dict)]
            except Exception as e:
                print(f"[WARNING] Advanced ranking hatasi: {e}")
        
        # Ä°ÅŸlem sÃ¼resi
        processing_time = (datetime.now() - start_time).total_seconds() * 1000
        
        response = PredictionResponse(
            suggestions=unique_suggestions,
            corrected_text=corrected_text,
            processing_time_ms=round(processing_time, 2),
            sources_used=sources_used
        )
        
        # WHATSAPP BENZERÄ°: Cache'e kaydetme - Devre dÄ±ÅŸÄ± (her karakter iÃ§in yeni Ã¶neri)
        # WhatsApp iPhone gibi Ã§alÄ±ÅŸmasÄ± iÃ§in cache kullanma
        # if not skip_cache and REDIS_AVAILABLE and cache and cache_key:
        #     try:
        #         response_dict = response.model_dump() if hasattr(response, 'model_dump') else response.dict()
        #         cache.set(cache_key, response_dict, ttl=3600)
        #     except Exception as e:
        #         print(f"[WARNING] Cache kaydetme hatasi: {e}")
        
        return response
    
    async def _get_ai_predictions(self, text: str, max_suggestions: int, sources_used: List[str]):
        """AI tahminlerini al"""
        try:
            suggestions = await transformer_predictor.predict(text, max_suggestions)
            if suggestions:
                sources_used.append("transformer")
            return suggestions
        except Exception as e:
            print(f"AI tahmin hatasÄ±: {e}")
            return []
    
    async def _get_trie_predictions(self, prefix: str, max_suggestions: int, sources_used: List[str]):
        """Trie Index ile ultra hÄ±zlÄ± arama"""
        suggestions = []
        
        if TRIE_AVAILABLE and trie_index and hasattr(trie_index, 'word_count') and trie_index.word_count > 0:
            try:
                results = trie_index.search(prefix, max_suggestions)
                for result in results:
                    if isinstance(result, dict):
                        suggestions.append(Suggestion(
                            text=result.get('word', ''),
                            type=result.get('type', 'dictionary'),
                            score=result.get('score', 8.0),
                            description=result.get('description', 'SÃ¶zlÃ¼k (Trie)'),
                            source=result.get('source', 'trie_index')
                        ))
                if suggestions:
                    sources_used.append('trie_index')
            except Exception as e:
                print(f"[WARNING] Trie search hatasi: {e}")
        
        return suggestions
    
    async def _get_search_predictions(self, prefix: str, max_suggestions: int, sources_used: List[str]):
        """SÃ¶zlÃ¼k arama sonuÃ§larÄ±nÄ± al - TEK HARF Ä°Ã‡Ä°N DE Ã‡ALIÅžIR! - GARANTÄ°LÄ°!"""
        try:
            # Prefix boÅŸ deÄŸilse ara
            prefix = prefix.strip() if prefix else ""
            if not prefix or len(prefix) == 0:
                return []
            
            # GARANTÄ°LÄ°: Her zaman local search yap
            suggestions = await elasticsearch_predictor.search(prefix, max_suggestions)
            
            # EÄŸer Ã¶neri yoksa, direkt large dictionary'den ara
            if not suggestions and LARGE_DICT_AVAILABLE and large_dictionary:
                try:
                    results = large_dictionary.search(prefix.lower(), max_suggestions)
                    if results:
                        for result in results:
                            suggestions.append(Suggestion(
                                text=result['word'],
                                type="dictionary",
                                score=result.get('score', 8.0),
                                description=f"SÃ¶zlÃ¼k (frekans: {result.get('frequency', 0)})",
                                source="large_dictionary"
                            ))
                except Exception as e:
                    print(f"[WARNING] Large dictionary direct search hatasi: {e}")
            
            if suggestions:
                source_name = "elasticsearch" if elasticsearch_predictor.es_client else "local_dictionary"
                if source_name not in sources_used:
                    sources_used.append(source_name)
            
            return suggestions
        except Exception as e:
            print(f"[ERROR] SÃ¶zlÃ¼k arama hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    async def _get_direct_large_dict_predictions(self, prefix: str, max_suggestions: int, sources_used: List[str]):
        """Large dictionary'den direkt arama - tum prefix uzunluklari"""
        suggestions = []
        try:
            if LARGE_DICT_AVAILABLE and large_dictionary:
                results = large_dictionary.search(prefix.lower(), max_suggestions)
                if results:
                    for result in results:
                        suggestions.append(Suggestion(
                            text=result['word'],
                            type="dictionary",
                            score=result.get('score', 9.0),
                            description=f"SÃ¶zlÃ¼k (frekans: {result.get('frequency', 0)})",
                            source="large_dictionary_direct"
                        ))
                    if suggestions and 'large_dictionary_direct' not in sources_used:
                        sources_used.append('large_dictionary_direct')
        except Exception as e:
            print(f"[WARNING] Direct large dict search hatasi: {e}")
        return suggestions
    
    async def _get_ngram_predictions(self, text: str, max_suggestions: int, sources_used: List[str]):
        """N-gram tahminlerini al"""
        try:
            if ADVANCED_NGRAM_AVAILABLE and advanced_ngram and hasattr(advanced_ngram, 'predict_next_word'):
                results = advanced_ngram.predict_next_word(text, max_suggestions)
                suggestions = []
                if results and isinstance(results, list):
                    for result in results:
                        if not isinstance(result, dict):
                            continue
                        txt = result.get('text') or result.get('word', '')
                        if not txt:
                            continue
                        suggestions.append(Suggestion(
                            text=txt,
                            type=result.get('type', 'ngram'),
                            score=result.get('score', 8.5),
                            description=result.get('description', 'N-gram tahmini'),
                            source=result.get('source', 'advanced_ngram')
                        ))
                if suggestions:
                    sources_used.append("advanced_ngram")
                return suggestions
            return []
        except Exception as e:
            print(f"[WARNING] N-gram prediction hatasi: {e}")
            return []
    
    async def _get_phrase_predictions(self, text: str, max_suggestions: int, sources_used: List[str]):
        """Phrase completion tahminlerini al"""
        try:
            if PHRASE_COMPLETION_AVAILABLE and phrase_completer and hasattr(phrase_completer, 'complete_phrase'):
                results = phrase_completer.complete_phrase(text, max_suggestions)
                suggestions = []
                if results and isinstance(results, list):
                    for result in results:
                        if isinstance(result, dict) and 'text' in result:
                            suggestions.append(Suggestion(
                                text=result['text'],
                                type=result.get('type', 'phrase'),
                                score=result.get('score', 8.0),
                                description=result.get('description', 'CÃ¼mle tamamlama'),
                                source=result.get('source', 'phrase_completion')
                            ))
                if suggestions:
                    sources_used.append("phrase_completion")
                return suggestions
            return []
        except Exception as e:
            print(f"[WARNING] Phrase completion hatasi: {e}")
            return []
    
    async def _get_domain_predictions(self, text: str, max_suggestions: int, sources_used: List[str]):
        """Domain-specific tahminlerini al"""
        try:
            if DOMAIN_DICT_AVAILABLE and domain_manager and hasattr(domain_manager, 'get_suggestions'):
                words = text.split()
                last_word = words[-1] if words else text
                context = None
                if CONTEXT_ANALYZER_AVAILABLE and context_analyzer and hasattr(context_analyzer, 'analyze'):
                    try:
                        context_analysis = context_analyzer.analyze(text)
                        if context_analysis and isinstance(context_analysis, dict):
                            # Context'ten domain Ã§Ä±kar
                            if context_analysis.get('topic') == 'customer_service':
                                context = 'customer_service'
                            elif context_analysis.get('topic') == 'technical':
                                context = 'technical'
                            elif context_analysis.get('topic') == 'ecommerce':
                                context = 'ecommerce'
                    except Exception as e:
                        print(f"[WARNING] Context analysis hatasi: {e}")
                
                results = domain_manager.get_suggestions(last_word, context, max_suggestions)
                suggestions = []
                if results and isinstance(results, list):
                    for result in results:
                        if isinstance(result, dict) and 'text' in result:
                            suggestions.append(Suggestion(
                                text=result['text'],
                                type=result.get('type', 'domain'),
                                score=result.get('score', 8.5),
                                description=result.get('description', 'Domain sÃ¶zlÃ¼ÄŸÃ¼'),
                                source=result.get('source', 'domain_dict')
                            ))
                if suggestions:
                    sources_used.append("domain_dict")
                return suggestions
            return []
        except Exception as e:
            print(f"[WARNING] Domain dictionary hatasi: {e}")
            return []
    
    async def _get_emoji_predictions(self, text: str, max_suggestions: int, sources_used: List[str]):
        """Emoji Ã¶nerilerini al"""
        try:
            if EMOJI_AVAILABLE and emoji_suggester and hasattr(emoji_suggester, 'suggest_emojis'):
                results = emoji_suggester.suggest_emojis(text, max_suggestions)
                suggestions = []
                if results and isinstance(results, list):
                    for result in results:
                        if isinstance(result, dict) and 'text' in result:
                            suggestions.append(Suggestion(
                                text=result['text'],
                                type=result.get('type', 'emoji'),
                                score=result.get('score', 8.0),
                                description=result.get('description', 'Emoji Ã¶nerisi'),
                                source=result.get('source', 'emoji')
                            ))
                if suggestions:
                    sources_used.append("emoji")
                return suggestions
            return []
        except Exception as e:
            print(f"[WARNING] Emoji suggestion hatasi: {e}")
            return []
    
    async def _get_template_predictions(self, text: str, max_suggestions: int, sources_used: List[str]):
        """Smart template Ã¶nerilerini al"""
        try:
            if SMART_TEMPLATES_AVAILABLE and smart_template_manager and hasattr(smart_template_manager, 'get_templates'):
                # Sadece "/" ile baÅŸlayan veya template kelimeleri iÃ§in
                if text.startswith('/') or any(word in text.lower() for word in ['sipariÅŸ', 'mÃ¼ÅŸteri', 'api', 'database']):
                    results = smart_template_manager.get_templates(text, max_suggestions)
                    suggestions = []
                    if results and isinstance(results, list):
                        for result in results:
                            if isinstance(result, dict) and 'text' in result:
                                suggestions.append(Suggestion(
                                    text=result['text'],
                                    type=result.get('type', 'template'),
                                    score=result.get('score', 9.0),
                                    description=result.get('description', 'AkÄ±llÄ± ÅŸablon'),
                                    source=result.get('source', 'smart_templates')
                                ))
                    if suggestions:
                        sources_used.append("smart_templates")
                    return suggestions
            return []
        except Exception as e:
            print(f"[WARNING] Smart template hatasi: {e}")
            return []
    
    def _merge_and_rank(self, suggestions: List[Suggestion], max_suggestions: int) -> List[Suggestion]:
        """SonuÃ§larÄ± birleÅŸtir ve sÄ±rala - iPhone benzeri yaygÄ±n kelime Ã¶nceliÄŸi"""
        if not suggestions:
            return []
        
        # DuplikatlarÄ± kaldÄ±r
        seen = set()
        unique_suggestions = []
        
        for sug in suggestions:
            if not sug or not sug.text:
                continue
            key = sug.text.lower().strip()
            if not key:
                continue
                
            if key not in seen:
                seen.add(key)
                unique_suggestions.append(sug)
            else:
                # Duplikat varsa skoru artÄ±r (daha iyi kaynak Ã¶ncelikli)
                existing = next((s for s in unique_suggestions if s.text.lower() == key), None)
                if existing:
                    existing.score = max(existing.score, sug.score) + 0.5
        
        # iPhone benzeri: yaygÄ±n kelimelere skor bonusu (hangi, merhaba, nasÄ±l vb. Ã¶ne Ã§Ä±kar)
        if COMMON_WORDS_AVAILABLE and is_common and first_word_common:
            for s in unique_suggestions:
                t = (s.text or "").strip()
                if not t:
                    continue
                if " " not in t and is_common(t):
                    s.score += 3.5
                elif first_word_common(t):
                    s.score += 2.0
        
        # Skora gÃ¶re sÄ±rala (en yÃ¼ksek skorlu Ã¶neriler Ã¶nce)
        unique_suggestions.sort(key=lambda x: x.score, reverse=True)
        
        return unique_suggestions[:max_suggestions]

orchestrator = HybridOrchestrator()

# ============================================
# RATE LIMITING
# ============================================

# Rate limiting iÃ§in basit cache
_rate_limit_cache = {}
_rate_limit_window = 60  # 60 saniye
_rate_limit_max_requests = 100  # Dakikada maksimum 100 istek

def _check_rate_limit(user_id: str) -> bool:
    """Rate limiting kontrolÃ¼"""
    import time
    current_time = time.time()
    
    # Eski kayÄ±tlarÄ± temizle
    _rate_limit_cache[user_id] = [
        req_time for req_time in _rate_limit_cache.get(user_id, [])
        if current_time - req_time < _rate_limit_window
    ]
    
    # Ä°stek sayÄ±sÄ±nÄ± kontrol et
    if len(_rate_limit_cache.get(user_id, [])) >= _rate_limit_max_requests:
        return False
    
    # Yeni isteÄŸi ekle
    if user_id not in _rate_limit_cache:
        _rate_limit_cache[user_id] = []
    _rate_limit_cache[user_id].append(current_time)
    
    return True

# WHATSAPP BENZERÄ°: WebSocket rate limiting Ã§ok esnek (her karakter iÃ§in Ã¶neri)
_ws_rate_limit = {}
_ws_rate_limit_window = 60
_ws_rate_limit_max_requests = 1000  # WhatsApp benzeri: Dakikada maksimum 1000 istek (her karakter iÃ§in)

def _check_ws_rate_limit(user_id: str) -> bool:
    """WebSocket rate limiting kontrolÃ¼"""
    import time
    current_time = time.time()
    
    _ws_rate_limit[user_id] = [
        req_time for req_time in _ws_rate_limit.get(user_id, [])
        if current_time - req_time < _ws_rate_limit_window
    ]
    
    if len(_ws_rate_limit.get(user_id, [])) >= _ws_rate_limit_max_requests:
        return False
    
    if user_id not in _ws_rate_limit:
        _ws_rate_limit[user_id] = []
    _ws_rate_limit[user_id].append(current_time)
    
    return True

# ============================================
# API ENDPOINTS
# ============================================

@app.get("/")
async def root():
    return {
        "message": "TextHelper ULTIMATE API",
        "version": "2.0.0",
        "status": "running",
        "architecture": "Hybrid: Transformer + Elasticsearch + FastAPI",
        "features": [
            "Transformer AI Predictions",
            "Elasticsearch Dictionary Search",
            "Hybrid Orchestration",
            "Spell Checking",
            "WebSocket Support"
        ],
        "endpoints": {
            "predict": "/predict",
            "websocket": "/ws",
            "learn": "/learn",
            "health": "/health",
            "docs": "/docs"
        }
    }

# Rate limiting iÃ§in basit cache
_rate_limit_cache = {}
_rate_limit_window = 60  # 60 saniye
_rate_limit_max_requests = 100  # Dakikada maksimum 100 istek

def _check_rate_limit(user_id: str) -> bool:
    """Rate limiting kontrolÃ¼"""
    import time
    current_time = time.time()
    
    # Eski kayÄ±tlarÄ± temizle
    _rate_limit_cache[user_id] = [
        req_time for req_time in _rate_limit_cache.get(user_id, [])
        if current_time - req_time < _rate_limit_window
    ]
    
    # Ä°stek sayÄ±sÄ±nÄ± kontrol et
    if len(_rate_limit_cache.get(user_id, [])) >= _rate_limit_max_requests:
        return False
    
    # Yeni isteÄŸi ekle
    if user_id not in _rate_limit_cache:
        _rate_limit_cache[user_id] = []
    _rate_limit_cache[user_id].append(current_time)
    
    return True

@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest, req: Request, user_id: str = "default"):
    """
    Hybrid tahmin endpoint'i
    Transformer + Elasticsearch sonuÃ§larÄ±nÄ± birleÅŸtirir
    """
    # Rate limiting kontrolÃ¼ (basit)
    if not _check_rate_limit(user_id):
        raise HTTPException(
            status_code=429,
            detail=f"Rate limit aÅŸÄ±ldÄ±. Maksimum {_rate_limit_max_requests} istek/{_rate_limit_window} saniye"
        )
    
    # Security: Input validation
    if SECURITY_AVAILABLE and security_manager:
        try:
            is_valid, error_msg = security_manager.validate_input(request.text)
            if not is_valid:
                raise HTTPException(status_code=400, detail=error_msg or "Invalid input")
            
            # Rate limiting
            client_ip = req.client.host if req.client else "unknown"
            if not security_manager.check_rate_limit(client_ip):
                raise HTTPException(
                    status_code=429,
                    detail="Rate limit exceeded. Please try again later."
                )
            
            # Sanitize input
            request.text = security_manager.sanitize_input(request.text)
        except HTTPException:
            raise
        except Exception as e:
            print(f"[WARNING] Security check hatasi: {e}")
    
    print(f"[DEBUG] API Request: text='{request.text}'", flush=True)
    response = await orchestrator.predict(
        text=request.text,
        max_suggestions=request.max_suggestions,
        use_ai=request.use_ai,
        use_search=request.use_search,
        user_id=user_id
    )
    
    # ML Ã¶ÄŸrenme (kullanÄ±cÄ± seÃ§imini bekliyoruz)
    # Bu endpoint'te sadece tahmin yapÄ±yoruz
    
    return response

# WHATSAPP BENZERÄ°: WebSocket rate limiting Ã§ok esnek (her karakter iÃ§in Ã¶neri)
_ws_rate_limit = {}
_ws_rate_limit_window = 60
_ws_rate_limit_max_requests = 1000  # WhatsApp benzeri: Dakikada maksimum 1000 istek (her karakter iÃ§in)

def _check_ws_rate_limit(user_id: str) -> bool:
    """WebSocket rate limiting kontrolÃ¼"""
    import time
    current_time = time.time()
    
    _ws_rate_limit[user_id] = [
        req_time for req_time in _ws_rate_limit.get(user_id, [])
        if current_time - req_time < _ws_rate_limit_window
    ]
    
    if len(_ws_rate_limit.get(user_id, [])) >= _ws_rate_limit_max_requests:
        return False
    
    if user_id not in _ws_rate_limit:
        _ws_rate_limit[user_id] = []
    _ws_rate_limit[user_id].append(current_time)
    
    return True

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket ile real-time Ã¶neriler - WHATSAPP BENZERÄ° (her karakter iÃ§in anlÄ±k Ã¶neri)"""
    await websocket.accept()
    
    try:
        while True:
            data = await websocket.receive_json()
            
            # WHATSAPP BENZERÄ°: Rate limiting daha esnek (her karakter iÃ§in Ã¶neri)
            user_id = data.get("user_id", "default")
            if not _check_ws_rate_limit(user_id):
                await websocket.send_json({
                    "error": f"Rate limit aÅŸÄ±ldÄ±. Maksimum {_ws_rate_limit_max_requests} istek/{_ws_rate_limit_window} saniye"
                })
                continue
            
            text = data.get("text", "").strip()
            context_message = data.get("context_message", None) # YENÄ°
            max_suggestions = data.get("max_suggestions", 80)
            use_ai = data.get("use_ai", True)
            use_search = data.get("use_search", True)
            
            try:
                # WHATSAPP BENZERÄ°: Her karakter iÃ§in anlÄ±k Ã¶neri (cache yok)
                # "a" -> "ak" -> "akÄ±" -> "akÄ±l" her adÄ±mda gÃ¼ncelleniyor
                print(f"[DEBUG] WS Request: text='{text}', context='{context_message}'", flush=True)
                response = await orchestrator.predict(
                    text=text,
                    context_message=context_message, # YENÄ°
                    max_suggestions=max_suggestions,
                    use_ai=use_ai,
                    use_search=use_search,
                    user_id=user_id
                )
                
                # WHATSAPP BENZERÄ°: AnlÄ±k gÃ¶nder (her karakter iÃ§in)
                response_dict = response.model_dump() if hasattr(response, 'model_dump') else response.dict()
                await websocket.send_json(response_dict)
            except Exception as e:
                print(f"[ERROR] Prediction loop hatasi: {e}", flush=True)
                # Client'a hata mesajÄ± gÃ¶nder ama baÄŸlantÄ±yÄ± koparma
                await websocket.send_json({"suggestions": [], "error": str(e)})
            
    except WebSocketDisconnect:
        # Normal disconnect - client baÄŸlantÄ±yÄ± kapattÄ±
        print("connection closed (normal)")
    except Exception as e:
        # DiÄŸer hatalar
        error_code = getattr(e, 'code', None)
        if error_code == 1001 or "disconnect" in str(e).lower():
            # 1001 = normal disconnect (client kapattÄ±)
            print("connection closed (normal)")
        else:
            print(f"WebSocket error: {e}")
            # Sadece baÄŸlantÄ± hala aÃ§Ä±ksa kapat
            try:
                if websocket.client_state.name != "DISCONNECTED":
                    await websocket.close()
            except Exception:
                pass  # Zaten kapatÄ±lmÄ±ÅŸ

@app.post("/learn")
async def learn_text(text: str, user_id: str = "default", selected_suggestion: Optional[str] = None):
    """Sistem Ã¶ÄŸrenme endpoint'i - Real-time learning"""
    # 1. ML Learning'den Ã¶ÄŸren
    if ML_LEARNING_AVAILABLE and ml_learning and hasattr(ml_learning, 'learn_from_interaction'):
        try:
            ml_learning.learn_from_interaction(
                user_id=user_id,
                input_text=text,
                selected_suggestion=selected_suggestion or "",
                context=text
            )
            print(f"[LEARN] ML ogrenme: {text} (kullanici: {user_id})")
        except Exception as e:
            print(f"[WARNING] ML learning hatasi: {e}")
    
    # 2. N-gram'dan Ã¶ÄŸren (YENÄ°!)
    if ADVANCED_NGRAM_AVAILABLE and advanced_ngram and hasattr(advanced_ngram, 'learn_from_text'):
        try:
            advanced_ngram.learn_from_text(text)
            if selected_suggestion:
                # SeÃ§ilen Ã¶neriyi de Ã¶ÄŸren
                full_text = f"{text} {selected_suggestion}"
                advanced_ngram.learn_from_text(full_text)
            print(f"[LEARN] N-gram ogrenme: {text}")
        except Exception as e:
            print(f"[WARNING] N-gram learning hatasi: {e}")
    
    # 3. Ranking'den Ã¶ÄŸren (YENÄ°!)
    if ADVANCED_RANKING_AVAILABLE and advanced_ranking and selected_suggestion and hasattr(advanced_ranking, 'record_click'):
        try:
            advanced_ranking.record_click(selected_suggestion)
            print(f"[LEARN] Ranking ogrenme: {selected_suggestion}")
        except Exception as e:
            print(f"[WARNING] Ranking learning hatasi: {e}")
    
    # Cache'i temizle (yeni Ã¶ÄŸrenilen bilgiler iÃ§in)
    if REDIS_AVAILABLE and cache and hasattr(cache, 'clear_pattern'):
        try:
            cache.clear_pattern("predict:*")
        except Exception as e:
            print(f"[WARNING] Cache clear hatasi: {e}")
    
    return {"status": "learned", "text": text, "user_id": user_id, "real_time": True}

@app.get("/health")
async def health():
    """Sistem saÄŸlÄ±k kontrolÃ¼ - DetaylÄ± Durum"""
    health_status = {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "2.1.0",
        "components": {}
    }
    
    # 1. Dictionary Status
    dict_size = 0
    if elasticsearch_predictor.local_dictionary:
        dict_size = len(elasticsearch_predictor.local_dictionary)
    
    if LARGE_DICT_AVAILABLE and large_dictionary:
        try:
            dict_size = large_dictionary.get_word_count()
        except:
            pass
            
    health_status["components"]["dictionary"] = {"status": "ok", "size": dict_size}
    
    # 2. Transformer Status
    if REAL_TRANSFORMER_AVAILABLE and transformer_model:
        try:
            info = transformer_model.get_model_info()
            health_status["components"]["transformer"] = {
                "status": "active" if info.get("loaded") else "standby",
                "details": info
            }
        except Exception as e:
            health_status["components"]["transformer"] = {"status": "error", "error": str(e)}
    else:
         health_status["components"]["transformer"] = {"status": "disabled"}
            
    # 3. Redis Status
    if REDIS_AVAILABLE and cache:
        health_status["components"]["redis"] = {"status": "connected", "type": "redis-py"}
    else:
        health_status["components"]["redis"] = {"status": "unavailable"}
             
    # 4. Elasticsearch Status
    if elasticsearch_predictor.es_client:
         health_status["components"]["elasticsearch"] = {"status": "connected"}
    else:
         health_status["components"]["elasticsearch"] = {"status": "disconnected"}
         
    return health_status

@app.post("/index_words")
async def index_words_to_elasticsearch():
    """Kelimeleri Elasticsearch'e index'le"""
    if not ES_MANAGER_AVAILABLE or not es_manager or not hasattr(es_manager, 'available') or not es_manager.available:
        return {"status": "error", "message": "Elasticsearch kullanÄ±lamÄ±yor"}
    
    # Kelimeleri hazÄ±rla
    words_data = []
    
    # BÃ¼yÃ¼k sÃ¶zlÃ¼kten al
    if LARGE_DICT_AVAILABLE and large_dictionary:
        for word in large_dictionary.words:
            words_data.append({
                'word': word,
                'frequency': large_dictionary.word_frequencies.get(word.lower(), 1),
                'category': 'general'
            })
    else:
        # VarsayÄ±lan sÃ¶zlÃ¼k
        for word in elasticsearch_predictor.local_dictionary:
            words_data.append({
                'word': word,
                'frequency': 1,
                'category': 'general'
            })
    
    # Index'le
    success = False
    if hasattr(es_manager, 'index_words'):
        try:
            success = await es_manager.index_words(words_data)
        except Exception as e:
            print(f"[ERROR] Index hatasi: {e}")
            return {"status": "error", "message": f"Index hatasi: {e}"}
    
    return {
        "status": "success" if success else "error",
        "words_indexed": len(words_data) if success else 0
    }

# ============================================
# BAÅžLATMA
# ============================================

# ============================================
# LIFESPAN (YENÄ° - Startup/Shutdown)
# ============================================


from fastapi import BackgroundTasks

def background_learn(user_id: str, text: str, selected_suggestion: str):
    """Arka planda Ã¶ÄŸrenme iÅŸlemi"""
    if ML_LEARNING_AVAILABLE and ml_learning:
        try:
            ml_learning.learn_from_interaction(
                user_id,
                text,
                selected_suggestion
            )
        except Exception as e:
            logger.error(f"Background learning hatasÄ±: {e}")

@app.post("/learn")
async def learn_interaction(feedback: FeedbackRequest, background_tasks: BackgroundTasks):
    """KullanÄ±cÄ± etkileÅŸiminden Ã¶ÄŸren (Fire-and-Forget)"""
    if ML_LEARNING_AVAILABLE and ml_learning:
        # Ana thread'i bekletmeden arka plana at
        background_tasks.add_task(
            background_learn,
            feedback.user_id,
            feedback.text,
            feedback.selected_suggestion
        )
        return {"status": "queued"}
    return {"status": "unavailable"}

# ============================================
# API VERSIONING (Standardization)
# ============================================

class CorrectionRequest(BaseModel):
    text: str
    user_id: Optional[str] = "default"

@app.post("/correct")
async def autocorrect_text(request: CorrectionRequest):
    """
    iPhone/WhatsApp tarzÄ± agresif otomatik dÃ¼zeltme.
    Fuzzy search + N-Gram context kullanÄ±r.
    """
    original = request.text
    corrected = original
    
    # Kelimeleri ayÄ±r
    words = original.split()
    if not words:
        return {"original": original, "corrected": original, "changed": False}
        
    # Son kelimeyi dÃ¼zelt (genelde yazÄ±lmakta olan)
    last_word = words[-1]
    
    # 1. Fuzzy Search ile en iyi eÅŸleÅŸmeyi bul
    if ADVANCED_FUZZY_AVAILABLE and advanced_fuzzy:
        suggestions = advanced_fuzzy.match(last_word, elasticsearch_predictor.local_dictionary if elasticsearch_predictor.local_dictionary else [], max_results=1)
        if suggestions and suggestions[0]['confidence'] > 0.8:  # YÃ¼ksek gÃ¼venilirlik
             words[-1] = suggestions[0]['word']
             corrected = " ".join(words)
    
    # 2. N-Gram Context ile kontrol et (daha akÄ±llÄ± dÃ¼zeltme)
    # Gelecekte eklenebilir: "merhaba nasÄ±lsÄ±n" gibi ikilileri kontrol et
             
    changed = corrected != original
    return {"original": original, "corrected": corrected, "changed": changed}

# V1 Router oluÅŸtur ve mevcut fonksiyonlarÄ± baÄŸla
router_v1 = APIRouter(prefix="/api/v1", tags=["v1"])

# Existing handlers bound to v1
router_v1.add_api_route("/predict", predict, methods=["POST"], response_model=PredictionResponse)
router_v1.add_api_route("/learn", learn_interaction, methods=["POST"])
router_v1.add_api_route("/health", health, methods=["GET"])
router_v1.add_api_route("/correct", autocorrect_text, methods=["POST"]) # YENI

app.include_router(router_v1)

if __name__ == "__main__":
    # Production: reloader kapalÄ± (2x RAM tasarrufu)
    # Development: DEV_MODE=true ile aÃ§
    is_dev = os.getenv("DEV_MODE", "false").lower() == "true"
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=is_dev  # Sadece geliÅŸtirme modunda aÃ§
    )

